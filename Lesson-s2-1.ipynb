{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Машинное обучение и нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Синапс нейронной сети / слой нейронной сети\n",
    "\n",
    "Синапс нейронной сети является аналогией синапса мозка. Сигнал, передающийся от других нейронов, аккумулируется с разным весом, и при достижении некоторого порога, генерирется выходной сигнал.\n",
    "\n",
    "В нейронных сетях обработка сигнала с предыдущих нейронов осуществляется путём линейного преобразования над входными сигналами. За активацию нейрона отвечает некоторая нелинейная функция, именуемая \"функция активации\", выход которой и является выходом используемой модели нейрона.\n",
    "\n",
    "**Слой** нейронной сети в большинстве случаев представляется комбинацией линейного преобразования и функии активации (в некоторых случаях слой может не иметь функции активации, или цеиком представлять собой нелинейное преобраование)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/synaps.png\" alt=\"Synaps\" height=30% width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейные операторы\n",
    "\n",
    "* Полносвязный слой (матричное умножение)\n",
    "* Свёрточный слой\n",
    "* Слой усреднения по окну (частный случай сверточного оператора)\n",
    "\n",
    "Далее представлен пример свёрточного слоя\n",
    "\n",
    "$$O_{i, j} = f(K*I_{i-s:i+s, j-s:j+s})$$\n",
    "\n",
    "$K$ - ядро свёртки  \n",
    "$I$ - входной тезнор  \n",
    "$I_{i-s:i+s, j-s:j+s}$ - срез тензора размера ядра свёртки с центром в точке (i, j)  \n",
    "$O_{i, j}$ - результат свёртки (значение выходного тензора в точке (i, j))  \n",
    "$f$ - функция активации\n",
    "\n",
    "<img src=\"images/convolution.jpeg\" alt=\"Synaps\" height=30% width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Функция активации\n",
    "\n",
    "В качестве функций активации могут выступать практическю любые дифференцируемые функции (но нужно понимать, что не с каждой функцией активации оптимизация параметров нейронной сети может быть произведена успешно.\n",
    "\n",
    "Наиболее популярными функциями активации являются:\n",
    "\n",
    "* ReLU\n",
    "* Sigmoid (сигмоида)\n",
    "* tanh (гиперболическийй тангенс)\n",
    "\n",
    "### ReLU (rectified linear unit)\n",
    "$$\n",
    "F(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "<img src=\"images/relu.png\" width=30% height=30% />\n",
    "\n",
    "### Сигмоида\n",
    "$$\n",
    "F(x) = {1 \\over 1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "<img src=\"images/sigmoid.png\" width=30% height=30% />\n",
    "\n",
    "### Гиперболический тангенс\n",
    "<img src=\"images/tanh.png\" width=30% height=30% />\n",
    "\n",
    "$$\n",
    "F(x) = {e^{2x}-1 \\over e^{2x}+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Нейронная сеть со скрытыми слоями\n",
    "\n",
    "Практически во всех задачах, решаемых при помощи нейронных сетей, не достаточно одного слоя нейронной сети.\n",
    "Один слой в описанном выше допущении одной функции активации не способен представить сложные зависимости, которые необходимы для решения задачи, для которой и обучается нейронная сеть.\n",
    "\n",
    "Нейронная сеть может включать в себя большое количество нейронов, соелинённых между собой в некоторой последовательности.Промежуточные слои называются скрытыми слоями.\n",
    "\n",
    "<img src=\"images/simple_neural_net.png\" alt=\"Synaps\" height=30% width=30%>\n",
    "$$ H = f_1(W_1*I)$$\n",
    "$$ O = f_2(W_2*H)$$\n",
    "\n",
    "$W_1$ и $W_2$ - матрицы весов, обучаемые параметры  \n",
    "$I$ - вектор входных признаков  \n",
    "$O$ - вектор выхода  \n",
    "$H$ - вектор скрытого состояния  \n",
    "$f$ - функция активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Softmax слой\n",
    "\n",
    "*Softmax* — это обобщение логистической функции для многомерного случая. Функция преобразует вектор z размерности K в вектор $\\sigma$  той же размерности, где каждая координата $\\sigma _{i}$ полученного вектора представлена вещественным числом в интервале [0,1] и сумма координат равна 1.\n",
    "\n",
    "$$\\sigma _{i} = {e^{z_i}\\over\\sum_{k=1}^Ke^{z_k}}$$\n",
    "\n",
    "Функция Softmax применяется в машинном обучении для задач классификации, когда количество возможных классов больше двух (для двух классов используется логистическая функция). Координаты $\\sigma_i$ полученного вектора при этом трактуются как вероятности того, что объект принадлежит к классу i.  \n",
    "Часто Softmax используется для последнего слоя глубоких нейронных сетей для задач классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Нейронная сеть с softmax слоем\n",
    "<img src=\"images/softmax.png\" width=80% height=80% />\n",
    "\n",
    "*Output Layer* возвращает вероятности принадлежности примера к каждому из 10 классов  \n",
    "*Hidden Layer 2* возвращает вектор скрытых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы обучения\n",
    "\n",
    "* **С учителем** - для входных данных известно, какое предсказание должны выдавать обученная нами модель.\n",
    "* **Без учителя** - конкретные значения выхода нейронной сети после обучения неизвестны (нейронная сеть сама учится группировать некоторые признаки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классы задач\n",
    "\n",
    "* **Классификация** - задача, в которой имеется множество объектов (ситуаций), разделённых некоторым образом на классы. Примеры:\n",
    "    * Задачи медицинской диагностики\n",
    "    * Предсказание месторождений полезных ископаемых\n",
    "    * Предсказание оттока клиентов\n",
    "    * Оптическое распознавание символов\n",
    "    * Обнаружение спама\n",
    "    * Предсказание возраста\n",
    "* **Регрессия** - задача, которая позволяет определить по известным характеристикам объекта значение некоторого его параметра. В отличие от задачи классификации значением параметра является не конечное множество классов, а множество действительных чисел. Примеры:\n",
    "    * Восстановление зависимости переменных\n",
    "    * Предсказание добычи\n",
    "    * Предсказание возраста\n",
    "* **Кластеризация** - задача, которая заключается в поиске независимых групп (кластеров) и их характеристик во всем множестве анализируемых данных. Решение этой задачи помогает лучше понять данные. Кроме того, группировка однородных объектов позволяет сократить их число, а следовательно, и облегчить анализ. Примеры:\n",
    "    * Разбиение клиентов на целевые группы\n",
    "    * Выделение групп людей на основе графа связей в социальных сетях\n",
    "    * Повышение релевантности ответов на поисковые запросы путем группировки веб-сайтов по смысловым значениям поискового запроса\n",
    "    * Кластеризация используется в сегментации изображений для определения границ и распознавания объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Подготовка данных. Разметка.\n",
    "\n",
    "Для задач, подразумевающих обучение с учителем требуется предварительная подготовка данных. Которая включает в себя как предобработку входных данных для нейронной сети, так и подготовка данных, которые будут использоваться в качестве заранее известного значения, к которому должно стремиться предсказание нейронной сети (GT - ground truth)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Табличные данные\n",
    "\n",
    "Табличные данные практически всегда требуют некоторой подготовки, и приведению их к некоторому унифицированному виду.\n",
    "\n",
    "Типичные действия при подготовке табличных данных включают в себя:\n",
    "\n",
    "* Исправление опечаток / ошибок в текстовых признаках (довольно частая проблема, когда производится набор текста)\n",
    "* Обработка пропусков в данных (порой эти пропуски могут быть не критичны, и данные могут быть использованы для обучения модели)\n",
    "* Приведение признаков к численному типу данных\n",
    "* Генерация новых признаков, на основе комбинации уже имеющихся.\n",
    "\n",
    "<img src=\"images/titanic.png\" width=80% height=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация изображений\n",
    "\n",
    "Зада классификации изображений - задача присвоения изображению одной категории.\n",
    "\n",
    "Если изображения являются синтетическими, т.е. сгенерированы каким-либо инструментом, то обычно заранее извество, что именно генерировалось на изображении, а значит для таким изображений категория известна заранее.\n",
    "\n",
    "Для реальных данных категория заранее может быть не известна. В таком случае важной стадией подготовки данных является **разметка**.\n",
    "Разметка данных для задач классификации является одной из сравнительно несложных. В этом процессе человек (или несколько людей) назначают для каждого изображения производит его анализ и назначает ему класс.\n",
    "\n",
    "> Стоит отметить, что анализ изображений может производиться и другой обученной нейронной сетью, но на данном этапе на это не стоит отвлекаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Задача детектирования\n",
    "\n",
    "Детектирование - поиск области (часто прямоугольной), занимаемой некоторыми объектами.\n",
    "\n",
    "В процессе разметки происходит поиск объектов, назначении этим объектам класса, и выделении прямоугольных областей, занимаемых этими объектами.\n",
    "\n",
    "<img src=\"images/detect.jpg\" width=80% height=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Задача сегментации\n",
    "\n",
    "Сегментация является наболее сложной задачей для получения разметки, так как вместо ограничивающих прямоугольных областей требуется задать контур объекта (что для некоторых объектов может быть крайне трудозатратно).\n",
    "\n",
    "Альтернативным вариантом может быть закрашивание областей на изображении, занимаемых тем или иным объектом на изображении.\n",
    "\n",
    "Для подобной разметки часто требуется специальное программное обеспечение, позволяющее ускорить процесс выделения объектов.\n",
    "\n",
    "<img src=\"images/segment.jpg\" width=80% height=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения\n",
    "\n",
    "Процесс обучения состоит из следующих шагов:\n",
    "\n",
    "1. Получение из датасета некоторой партии объектов (далее batch, батч), а также GT (ground truth) для них.\n",
    "2. Подача объектов на вход нейронной сети и получение предсказания модели (Prediction / Pred.).\n",
    "3. Вычисление ошибки между Pred. и  GT при помощи функции ошибки loss_func (loss function).\n",
    "4. Распространение ошибки по сети (подробно рассмотрим в следующем уроке)\n",
    "5. Обновление параметров (весов) модели на основе распространённой ошибки.\n",
    "6. Если прошло достаточное количество итераций, или ошибка предсказания стала меньше некоторого значения, заверщаем обучение, иначе возвращаемся к пункту 1.\n",
    "\n",
    "В ходе обучения может возникнуть ситуация, что сеть функция ошибки более не уменьшается, но качество предсказания модели плохое. Возможна и другая ситуация, при которой сеть при довольно низком значении функции ошибки, имеет низкое качество предсказаний.\n",
    "\n",
    "<img src=\"images/Overfitting.curve.png\" width=30% height=30% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Недообучение / Переобучение\n",
    "\n",
    "**Недообучение** — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.\n",
    "\n",
    "**Переобучение** (overtraining, overfitting) — нежелательное явление, возникающее при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке. Переобучение возникает при использовании избыточно сложных моделей.\n",
    "\n",
    "<img src=\"images/Overfitting.svg.png\" width=80% height=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Возможные решения при переобучении:\n",
    "* Увеличение количества данных в наборе;\n",
    "* Уменьшение количества параметров модели (количество параметров модели (весов) была в 2 - 3 раза меньше числа примеров обучающего множества);\n",
    "* Добавление регуляризации / увеличение коэффициента регуляризации.\n",
    "\n",
    "### Возможные решения при недообучении:\n",
    "* Добавление новых параметров модели;\n",
    "* Использование для описания модели функций с более высокой степенью;\n",
    "* Уменьшение коэффициента регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Аугментация данных\n",
    "\n",
    "**Аугментация данных** (data augmentation) – это методика создания дополнительных обучающих данных из имеющихся данных. Для достижения хороших результатов глубокие сети должны обучаться на очень большом объеме данных. Следовательно, если исходный обучающий набор содержит ограниченное количество изображений, необходимо выполнить аугментацию, чтобы улучшить результаты модели.\n",
    "\n",
    "Примеры аугментаций при работе с изображениями:\n",
    "\n",
    "* Геометрические (афинные, проективные, ...);\n",
    "* Яркостные/цветовые;\n",
    "* Замена фона;\n",
    "* Искажения, характерные для решаемой задачи: блики, шумы, размытие и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Отражение\n",
    "<img src=\"images/aug_flip.jpeg\" width=60% height=60% />\n",
    "\n",
    "### Поворот\n",
    "<img src=\"images/aug_rot.jpeg\" width=60% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Случайное образание\n",
    "<img src=\"images/aug_crop.jpeg\" width=60% height=60% />\n",
    "\n",
    "### Шумы\n",
    "<img src=\"images/aug_noises.png\" width=60% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Аугментация с помощью GAN (Generative adversarial network - Генеративно-состязательная сеть)\n",
    "<img src=\"images/aug_noises.png\" width=60% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Дообучение\n",
    "\n",
    "Ещё одним подходом при обучении моделей является дообучение. Данный подход подразумевает, что у вас имеется обученная на некотором датасете модель (при этом нет никаких ограничений на то, на каком именно датасете обучалась модель, и какую задачу она решала). Интуиция, стоящая за подобным подходом, заключается в том, что уже обученная модель умеет извлекать какие-то признаки из входных данных. Соответственно ей может быть проще обучиться на новых данных.\n",
    "\n",
    "Во многих задачах данный подход показал себя достаточно действенным, значительно сократив время обучения моделей, порой позволяя увеличить качество предсказаний результирующей модели.\n",
    "\n",
    "<img src=\"images/finetuning_1.png\" width=60% height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструменты для работы с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Генераторы в Python\n",
    "Генераторы и итераторы представляют собой инструменты, которые, как правило, используются для поточной обработки данных.   \n",
    "  \n",
    "Итератор представляет собой объект перечислитель, который для данного объекта выдает следующий элемент, либо бросает исключение, если элементов больше нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Создание итератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Из списка\n",
    "it = iter([1, 2, 5, 3])\n",
    "print(it)\n",
    "# Перечисление циклом for\n",
    "for i in it:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Перечисление с помощью функции next\n",
    "it = iter([1, 2, 5, 3])\n",
    "while True:\n",
    "    print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Создание в функции\n",
    "def fun_iter(val):\n",
    "    s = 1\n",
    "    while True:\n",
    "        s = s * val\n",
    "        yield s\n",
    "        \n",
    "fit = fun_iter(2)\n",
    "for i in range(4):\n",
    "    print(next(fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Библиотека OpenCV\n",
    "\n",
    "<img src=\"images/opencv.png\" width=15% height=15% />\n",
    "\n",
    "**OpenCV** (Open Source Computer Vision Library) — библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом. Реализована на C/C++, также разрабатывается для Python, Java, Ruby, Matlab, Lua и других языков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Чтение картинки (чтение происходит в цветовой модели BGR)\n",
    "# img_bgr = cv2.imread('data/Lenna.png')\n",
    "img_bgr = cv2.imread('data/Vanya.jpg')\n",
    "print(img_bgr.shape)\n",
    "plt.imshow(img_bgr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Для перевода в RGB можно либо воспользоваться функцией opencv, либо инвертировать каналы\n",
    "img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "img = img_bgr[:, :, ::-1]  # Каналы - третье измерение изображения\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Есть возможность сразу читать в цветовой модели Grayscale\n",
    "img_gray = cv2.imread('data/Vanya.jpg', 0)\n",
    "print(img_gray.shape)\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Преобразования изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поворот изображения на 90 градусов\n",
    "img_rot = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "# Отражение по горизонтали (0 - по вертикали)\n",
    "img_flip = cv2.flip(img, 1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_rot)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_flip)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Поворот на произвольный угол с помощью афинных преобразований\n",
    "M = cv2.getRotationMatrix2D((128, 128), 30, 1)  # Указывается центр, угол поворота, масштаб\n",
    "img_rot = cv2.warpAffine(img, M, (256, 256))\n",
    "plt.imshow(img_rot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Изменение перспективы\n",
    "# pts1 = np.float32([[56, 65],[368, 52],[28, 512],[412, 512]])\n",
    "# pts2 = np.float32([[0, 0], [512, 0], [0, 512], [512, 512]])\n",
    "pts1 = np.float32([[ 28. ,  32.5],\n",
    "                   [184. ,  26. ],\n",
    "                   [ 14. , 256. ],\n",
    "                   [256. , 256. ]])\n",
    "pts2 = np.float32([[0, 0], [256, 0], [0, 256], [256, 256]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "img_persp = cv2.warpPerspective(img, M, (256, 256))\n",
    "\n",
    "# Нарисуем исходные точки (изменяет исходное изображение)\n",
    "img_copy = img.copy()\n",
    "for pt in pts1:\n",
    "    cv2.circle(img_copy, tuple(pt.astype(int)), 4, (0, 255, 0), 8)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_copy)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_persp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Изменение размера\n",
    "img_sc = cv2.resize(img, (512, 256))\n",
    "plt.imshow(img_sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Размытие\n",
    "img_bl = cv2.blur(img, (17, 5))\n",
    "plt.imshow(img_bl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Задания\n",
    "\n",
    "1. Скачать датасет [Nails segmentation](https://www.kaggle.com/vpapenko/nails-segmentation#1eecab90-1a92-43a7-b952-0204384e1fae.jpg). Составить список из пар (<имя изображения>, <маска>) для всех данных, используя функцию os.listdir() или glob.glob().  \n",
    "2. Создать генератор, который на каждой итерации возвращает пару списков из заданного количества (аргумент функции) изображений и масок к ним (итератор должен перемешивать примеры).  \n",
    "3. Добавить в генератор случайную аугментацию (каждая применяется случайно). После преобразований все изображения должны иметь одинаковый размер. *Обратите внимание, что большинство преобразований должны применяться одинаково к изображению и маске*\n",
    "    1. Поворот на случайный угол\n",
    "    2. Отражение по вертикали, горизонтали\n",
    "    3. Вырезание части изображения\n",
    "    4. Размытие  \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
