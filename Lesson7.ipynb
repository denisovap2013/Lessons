{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Введение Машинное обучение\n",
    "### Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Соревнование Kaggle \"Titanic: Machine Learning from Disaster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df_main = pd.read_csv('data/titanic/train.csv')\n",
    "df_test = pd.read_csv('data/titanic/test.csv')\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep_x = df_main.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_prep_x_tst = df_test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df_prep_y = df_main['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Исходная таблица содержит текстовые и категориальные данные,\n",
    "# что не очень подходит для обработки. Поэтому сначала переводим\n",
    "# всё в некоторый численный эквивалент.\n",
    "#\n",
    "# Например, признак \"Пол\", можно разделить на два бинарных признака:\n",
    "# признак \"female\" и признак \"male\" (для данного примера это, как правило,\n",
    "# взаимоисключающие признаки, но в общем случае категорий может быть больше чем две)\n",
    "\n",
    "# Также, несмотря на то, что признак \"Pclass\" является числовым,\n",
    "# он всё ещё является категориальным и не очень подходит для анализа.\n",
    "\n",
    "def prepare_num(df):\n",
    "    df_num = df.drop(['Sex', 'Embarked', 'Pclass'], axis=1)\n",
    "    df_sex = pd.get_dummies(df['Sex'])\n",
    "    df_emb = pd.get_dummies(df['Embarked'], prefix='Emb')\n",
    "    df_pcl = pd.get_dummies(df['Pclass'], prefix='Pclass')\n",
    "\n",
    "    df_num = pd.concat((df_num, df_sex, df_emb, df_pcl), axis=1)\n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_prep_x_num = prepare_num(df_prep_x)\n",
    "df_prep_x_num_tst = prepare_num(df_prep_x_tst)\n",
    "df_prep_x_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Заполняем пустые значения\n",
    "df_prep_x_num = df_prep_x_num.fillna(df_prep_x_num.median())\n",
    "df_prep_x_num_tst = df_prep_x_num_tst.fillna(df_prep_x_num.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_x = scaler.fit_transform(df_prep_x_num)\n",
    "scaled_x_tst = scaler.transform(df_prep_x_num_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Общий синтаксис моделей sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конструктор с заданием параметров\n",
    "```python\n",
    "model = ...\n",
    "```\n",
    "\n",
    "Обучение модели\n",
    "```python\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "Предсказание результатов\n",
    "```python\n",
    "y_predict = model.predict(X_test)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Метод главных компонент (PCA)\n",
    "\n",
    "Метод главных компонент позволяет одновременно избавиться от сильно скоррелированных признаков, так как вектора базиса пространства, на которое они проецируются, будут ортогональными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=2)\n",
    "squeezed = model.fit_transform(scaled_x)\n",
    "\n",
    "mask_survived = (df_prep_y == 1)\n",
    "mask_not_survived = (df_prep_y == 0)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(squeezed[mask_survived][:, 0], squeezed[mask_survived][:, 1], color='green', label='Survived')\n",
    "plt.scatter(squeezed[mask_not_survived][:, 0], squeezed[mask_not_survived][:, 1], color='red', marker='x', alpha=0.4,\n",
    "           label='Not survived')\n",
    "\n",
    "plt.xlabel(df_prep_x_num.columns[0])\n",
    "plt.ylabel(df_prep_x_num.columns[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# t-SNE\n",
    "t-SNE (t-distributed Stohastic Neighbor Embedding), метод отображения из многомерного признакового пространства на плоскость (или в 3D), чтобы точки, которые были далеко друг от друга, на плоскости тоже оказались удаленными, а близкие точки – также отобразились на близкие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(n_components=2)\n",
    "np.random.seed(123)\n",
    "squeezed = model.fit_transform(scaled_x)\n",
    "\n",
    "mask_survived = (df_prep_y == 1)\n",
    "mask_not_survived = (df_prep_y == 0)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(squeezed[mask_survived][:, 0], squeezed[mask_survived][:, 1], color='green', label='Survived')\n",
    "plt.scatter(squeezed[mask_not_survived][:, 0], squeezed[mask_not_survived][:, 1], color='red', marker='x', alpha=0.4,\n",
    "           label='Not survived')\n",
    "\n",
    "plt.xlabel(df_prep_x_num.columns[0])\n",
    "plt.ylabel(df_prep_x_num.columns[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Метод ближайших соседей (k-NN)\n",
    "\n",
    "Метод k-ближайших соседей (k-nearest neighbors algorithm) — метрический алгоритм для автоматической классификации объектов или регрессии.\n",
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    "1. Вычислить расстояние до каждого из объектов обучающей выборки\n",
    "2. Отобрать  объекты обучающей выборки, расстояние до которых минимально\n",
    "3. Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Сгенерируем данные с 2 признаками\n",
    "np.random.seed(18182)\n",
    "data_test = np.random.rand(300, 2)\n",
    "data_train = np.random.rand(1000, 2)\n",
    "# Обозначим как позитивные данные в радиусе 0.3 от точки (0.5; 0.5)\n",
    "label_train = (((data_train - 0.5) ** 2).sum(axis=1) < 0.3 ** 2).astype(float)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data_train[:, 0][label_train == 0], data_train[:, 1][label_train == 0], color='blue')\n",
    "plt.scatter(data_train[:, 0][label_train == 1], data_train[:, 1][label_train == 1], color='red')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(data_test[:, 0], data_test[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(data_train, label_train)\n",
    "predict = model.predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Дерево решений (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "model.fit(df_prep_x_num, df_prep_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "tree.plot_tree(model, feature_names=df_prep_x_num.columns, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Энтропия (степень хаоса или неопределенности в системе)\n",
    "$$\n",
    "S = -{\\sum_{n}p_ilog_2p_i}\n",
    "$$\n",
    "n - число классов  \n",
    "$p_i$ - вероятность i класса\n",
    "$$\n",
    "p_0 = {549 \\over 891} = 0.6161\n",
    "$$  \n",
    "\n",
    "$$\n",
    "p_1 = {342 \\over 891} = 0.3838\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "S_0 =  -p_0log_2p_0 - p_1log_2p_1 = 0.9607\n",
    "$$\n",
    "\n",
    "### Прирост информации\n",
    "$$\n",
    "IG = S_0 - \\sum_q{N_i\\over N}S_i\n",
    "$$\n",
    "q - число групп после разбиения  \n",
    "$N_i$ – число элементов выборки\n",
    "\n",
    "$$\n",
    "IG = 0.891 - {314\\over891}*0.824 - {577\\over891}*0.699 = 0.1479\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "features = df_prep_x_num.columns\n",
    "# Добавление сортировки по важности\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Важность признаков')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Относительная важность')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=4, criterion='entropy')\n",
    "model.fit(data_train, label_train)\n",
    "predict = model.predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = w_0 + \\sum_{i=1}^m w_ix_i\n",
    "$$\n",
    "\n",
    "$$x_0 = 1$$\n",
    "\n",
    "$$\n",
    "y = \\sum_{i=0}^m w_ix_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{y} = X \\vec{w} + \\epsilon\n",
    "$$\n",
    "\n",
    "$\\vec{y}$ – объясняемая (или целевая) переменная  \n",
    "$\\vec{w}$ – вектор параметров модели (веса)  \n",
    "X – матрица признаков  \n",
    "$\\epsilon$ –  случайная переменная, соответствующая случайной, непрогнозируемой ошибке модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ошибка модели\n",
    "Метод наименьших квадратов - минимизация среднеквадратичной ошибки между реальным значением зависимой переменной и прогнозом, выданным моделью:\n",
    "$$\n",
    "L(X, \\vec{y}, \\vec{w}) = {1\\over2n}\\sum_{i=1}^n(y_i-\\vec{w}^T\\vec{x}_i)^2 = {1\\over2n} ||\\vec y - X \\vec w||_2^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\partial L \\over \\partial \\vec w} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация\n",
    "w может принимать большие значения, что приведёт к нестабильной оценке параметров модели, т.е. добавление нового наблюдения в набор тренировочных данных приведёт к совершенно другому решению. Одним из способов борьбы с этим является регуляризация. Один из вариантов - регуляризация Тихонова:\n",
    "$$\n",
    "L(X, \\vec{y}, \\vec{w}) = {1\\over2n} ||\\vec y - X \\vec w||_2^2 + ||\\Gamma \\vec w || ^2\n",
    "$$\n",
    "\n",
    "$\\Gamma$ - матрица Тихонова (коэффициент регуляризации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный классификатор:\n",
    "$$\n",
    "a(\\vec x) = sign(\\vec w^Tx)\n",
    "$$\n",
    "sign() - функция, возвращающая знак своего аргумента  \n",
    "$a(\\vec x)$ - ответ классификатора (1 - целевой клас, -1 - отрицательный пример)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Логистическая регрессия является частным случаем линейного классификатора, но она может выражать вероятность отнесения функции к положительному классу ($p_+$):\n",
    "$$\n",
    "p_+ = P(y_i = 1| \\vec x_i, \\vec w)\n",
    "$$\n",
    "P(X) - вероятность события X\n",
    "\n",
    "$f(\\vec x_i, \\vec w) = \\vec x_i \\vec w = 0$ - разделяющая плоскость  \n",
    "f > 0 - класс \"+\"  \n",
    "f < 0 - класс \"-\"  \n",
    "f = 0 - непоределённость  \n",
    "\n",
    "Но давнные функции имеют разные пределы:  \n",
    "$f \\in (-\\infty ; \\infty)$  \n",
    "$P \\in [0 ; 1]$\n",
    "\n",
    "Введём функцию отношения вероятностей:\n",
    "$$\n",
    "OR(X) = {P(X) \\over 1 - P(X)}\n",
    "$$\n",
    "$OR \\in (0 ; \\infty)$, а $ln(OR) \\in (-\\infty ; \\infty)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Таким образом\n",
    "$log(OR_+) = \\vec w^T \\vec x_i $ или $OR_+ = e^{\\vec w^T \\vec x_i }$\n",
    "\n",
    "$$\n",
    "p_+ = {OR_+ \\over 1 + OR_+} = {e^{\\vec w^T \\vec x_i } \\over 1 + e^{\\vec w^T \\vec x_i }} = {1 \\over 1 + e^{-\\vec w^T \\vec x_i }} = \\sigma(\\vec w^T \\vec x_i )\n",
    "$$\n",
    "$\\sigma(x)$ - сигмоид-функция \n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/a/ac/Logistic-curve.png)\n",
    "\n",
    "Вероятность отнесения функции к отрицательному классу:\n",
    "$$\n",
    "p_- = P(y_i = -1| \\vec x_i, \\vec w) = \\sigma(-\\vec w^T \\vec x_i  )\n",
    "$$\n",
    "\n",
    "Обобщение:\n",
    "$$\n",
    "P(y = y_i| \\vec x_i, \\vec w) = \\sigma(y_i\\vec w^T \\vec x_i  )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=0.1, solver='lbfgs')\n",
    "model.fit(scaled_x, df_prep_y)\n",
    "\n",
    "y_pred = model.predict(scaled_x_tst)\n",
    "print('Классы:', y_pred[:4])\n",
    "y_proba = model.predict_proba(scaled_x_tst)\n",
    "print('Вероятности:\\n', y_proba[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# В данном случае модель на смогла подобрать разделяющую гиперплоскость\n",
    "model = LogisticRegression(C=0.1, solver='lbfgs')\n",
    "model.fit(data_train, label_train)\n",
    "predict = model.predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Мы можем модифицировать признаки.\n",
    "# Например перейти к полярным координатам\n",
    "\n",
    "def cart2pol(data_points):\n",
    "    rs = np.sqrt(np.sum(data_points ** 2, axis=1))  # sqrt(x ** 2 + y ** 2)\n",
    "    phi = np.arctan2(data_points[:, 1], data_points[:, 0])\n",
    "    return np.stack([rs, phi], axis=1)\n",
    "\n",
    "\n",
    "data_train_polar = cart2pol(data_train - [0.5, 0.5])\n",
    "data_test_polar = cart2pol(data_test - [0.5, 0.5])\n",
    "\n",
    "model = LogisticRegression(C=1, solver='lbfgs')\n",
    "model.fit(data_train_polar, label_train)\n",
    "predict = model.predict(data_test_polar)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Случайный лес\n",
    "Алгоритм:\n",
    "1. Сгенерировать подвыборку из данных\n",
    "2. Построить решающее дерево  по подвыборке\n",
    "3. Повторить шаги 1, 2 K раз\n",
    "4. Результат принимается как результат большинства (классификация) или среднему (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=4, criterion='entropy')\n",
    "model.fit(data_train, label_train)\n",
    "predict = model.predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# XGBoost (фреймворк)\n",
    "\n",
    "Бустинг - построение деревьев для минимизации ошибки имеющегося ансамбля моделей:\n",
    "\n",
    "Алгоритм для K шага:\n",
    "1. Сгенерировать подвыборку из данных\n",
    "2. Построить решающее дерево  по подвыборке. Целевая величина $y - pred_{K-1}$, где $pred_{K-1}$ - предсказание комбинации прошлых деревьев\n",
    "3. Добавить новое дерево к имеющемуся результату из комбинации прошлых деревьев так, чтобы минимизировать ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(n_estimators=20, max_depth=4, criterion='entropy')\n",
    "model.fit(data_train, label_train)\n",
    "predict = model.predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_test[:, 0][predict == 0], data_test[:, 1][predict == 0], color='blue')\n",
    "plt.scatter(data_test[:, 0][predict == 1], data_test[:, 1][predict == 1], color='red')\n",
    "# Отрисовка круга происходит через создание фигуры и добавления её на график\n",
    "circle = plt.Circle((0.5, 0.5), 0.3, color='g', fill=False)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn clustering](https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_0011.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# K-means\n",
    "\n",
    "Алгоритм:  \n",
    "1. Выбирается количество кластеров (k)  \n",
    "2. Случайным образом выбираются k точек, как центры кластеров  \n",
    "3. Для всех точек выборки определяется к какому центру они ближе  \n",
    "4. Переместить центры кластеров в центры выборок  \n",
    "5. Повторять последние два шага фиксированное число раз, либо до тех пор пока центроиды не \"сойдутся\" (обычно это значит, что их смещение относительно предыдущего положения не превышает какого-то заранее заданного небольшого значения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "clusters = model.fit_predict(data_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for cl in np.unique(clusters):\n",
    "    data_ = data_test[clusters == cl]\n",
    "    plt.scatter(data_[:, 0], data_[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DBSCAN\n",
    "\n",
    "Алгоритм DBSCAN (Density-based spatial clustering of applications with noise) рассматривает кластеры как области высокой плотности, разделенные областями низкой плотности. Из-за этого довольно общего представления кластеры, найденные DBSCAN, могут иметь любую форму, в отличие от k-means, которые предполагают, что кластеры имеют выпуклую форму.  \n",
    "Этот алгоритм позволяет выделять произвольное количество кластеров, основываясь на расстоянии между ними. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model = DBSCAN(eps=0.08, min_samples=1)\n",
    "clusters = model.fit_predict(data_test)\n",
    "print(np.unique(clusters).size, 'кластеров')\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for cl in np.unique(clusters):\n",
    "    data_ = data_test[clusters == cl]\n",
    "    plt.scatter(data_[:, 0], data_[:, 1], label='Кластер {}'.format(cl))\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ресурсы для углублённого изучения темы\n",
    "\n",
    "* [Открытый курс машинного обучения Open Data Science](https://habr.com/ru/company/ods/blog/322626/)\n",
    "* [Видеолекции ШАД Воронцова](https://yandexdataschool.ru/edu-process/courses/machine-learning)\n",
    "* [Классический курс по машинному обучению. Включает в себя как элементы классического ML так и нейронные сети](https://www.coursera.org/learn/machine-learning)\n",
    "* [Лекции об инструментах, которые нужны, чтобы начать применять ML на практике](https://www.dataschool.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Задания\n",
    "\n",
    "1. Разделите данные Титаника (*train.csv*) на тренировочную, валидационную и тестовую часть. С помощью валидационной части подберите гиперпараметры для моделей Random Forest, XGBoost, Logistic Regression и KNN. Получите точность этих моделей на тестовой части.\n",
    "2. С помощью RandomForest выберите 2, 4, 8 самых важных признаков и проверьте точность моделей только на этих признаках.\n",
    "3. Используя координаты скважин из файла *wells_info.csv* разделите их на кластера с помощью любых 4 методов и отобразите разделение. Параметры подбираются самостоятельно.\n",
    "4. Приведите отобранные в 6.1 задании признаки из файла *wells_info_with_prod.csv* в двумерное пространство. Выделите цветом добычу с этой скважины."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
